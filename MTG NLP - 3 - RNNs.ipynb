{"cells":[{"cell_type":"markdown","metadata":{"id":"ZLogUU8VJGga"},"source":["# Recurrent neural networks for NLP"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":478,"status":"ok","timestamp":1719861731860,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"Gcc9r4tiJGgd"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"ejkbd9cUJGge"},"source":["## Dataset retrieval\n","The file cards_nlp.csv must be available in the given path. Run the MTG NLP - 0 if not present.\n","\n","Get all cards and also lets load the Gemsin embedding for MTG."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":794},"executionInfo":{"elapsed":5868,"status":"ok","timestamp":1719861738186,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"kTK1H3EXJGgf","outputId":"3c213915-e41d-4c6a-9ead-68722ae3badb"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 28941 unique cards/documents\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>artist</th>\n","      <th>colorIdentity</th>\n","      <th>colors</th>\n","      <th>convertedManaCost</th>\n","      <th>edhrecRank</th>\n","      <th>edhrecSaltiness</th>\n","      <th>flavorText</th>\n","      <th>keywords</th>\n","      <th>legalities</th>\n","      <th>...</th>\n","      <th>power</th>\n","      <th>rarity</th>\n","      <th>rulings</th>\n","      <th>setCode</th>\n","      <th>subtypes</th>\n","      <th>supertypes</th>\n","      <th>text</th>\n","      <th>toughness</th>\n","      <th>type</th>\n","      <th>types</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Lius Lasahido</td>\n","      <td>U</td>\n","      <td>U</td>\n","      <td>7.0</td>\n","      <td>9173.0</td>\n","      <td>0.44</td>\n","      <td>He answers questions as readily as he asks the...</td>\n","      <td>['Flying', 'Hexproof']</td>\n","      <td>{'commander': 'Legal', 'duel': 'Legal', 'legac...</td>\n","      <td>...</td>\n","      <td>5</td>\n","      <td>mythic</td>\n","      <td>[{'date': '2016-01-22', 'text': 'A spell that ...</td>\n","      <td>POGW</td>\n","      <td>Sphinx</td>\n","      <td>None</td>\n","      <td>This spell can't be countered.\\nFlying, hexpro...</td>\n","      <td>5</td>\n","      <td>Creature — Sphinx</td>\n","      <td>Creature</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Jesper Myrfors</td>\n","      <td>R</td>\n","      <td>R</td>\n","      <td>3.0</td>\n","      <td>3003.0</td>\n","      <td>0.30</td>\n","      <td>To become king of the Goblins, one must assass...</td>\n","      <td>['None']</td>\n","      <td>{'commander': 'Legal', 'duel': 'Legal', 'legac...</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>rare</td>\n","      <td>[{'date': '2005-08-01', 'text': 'Goblin King n...</td>\n","      <td>3ED</td>\n","      <td>Goblin</td>\n","      <td>None</td>\n","      <td>Other Goblins get +1/+1 and have mountainwalk.</td>\n","      <td>2</td>\n","      <td>Creature — Goblin</td>\n","      <td>Creature</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Drew Baker</td>\n","      <td>G</td>\n","      <td>G</td>\n","      <td>1.0</td>\n","      <td>10754.0</td>\n","      <td>0.00</td>\n","      <td>None</td>\n","      <td>['Morbid']</td>\n","      <td>{'commander': 'Legal', 'duel': 'Legal', 'legac...</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>common</td>\n","      <td>[{'date': '2011-09-22', 'text': 'You can choos...</td>\n","      <td>ISD</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>Search your library for a basic land card, rev...</td>\n","      <td>0</td>\n","      <td>Sorcery</td>\n","      <td>Sorcery</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Jason Chan</td>\n","      <td>RG</td>\n","      <td>RG</td>\n","      <td>5.0</td>\n","      <td>21203.0</td>\n","      <td>0.00</td>\n","      <td>\"May the earth rise up to meet you.\"</td>\n","      <td>['Cycling']</td>\n","      <td>{'commander': 'Legal', 'duel': 'Legal', 'legac...</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>common</td>\n","      <td>[{'date': '2008-10-01', 'text': 'Cycling is an...</td>\n","      <td>ARB</td>\n","      <td>Minotaur</td>\n","      <td>None</td>\n","      <td>When this_card enters the battlefield, it deal...</td>\n","      <td>4</td>\n","      <td>Creature — Minotaur</td>\n","      <td>Creature</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Scott M. Fischer</td>\n","      <td>W</td>\n","      <td>W</td>\n","      <td>3.0</td>\n","      <td>1921.0</td>\n","      <td>1.72</td>\n","      <td>The law is meant to ensure that people kill ea...</td>\n","      <td>['None']</td>\n","      <td>{'brawl': 'Legal', 'commander': 'Legal', 'duel...</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>uncommon</td>\n","      <td>[{'date': '2019-07-12', 'text': 'If you cast a...</td>\n","      <td>M20</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>Each player can't cast more than one spell eac...</td>\n","      <td>0</td>\n","      <td>Enchantment</td>\n","      <td>Enchantment</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 23 columns</p>\n","</div>"],"text/plain":["   Unnamed: 0            artist colorIdentity colors  convertedManaCost  \\\n","0           0     Lius Lasahido             U      U                7.0   \n","1           1    Jesper Myrfors             R      R                3.0   \n","2           2        Drew Baker             G      G                1.0   \n","3           3        Jason Chan            RG     RG                5.0   \n","4           4  Scott M. Fischer             W      W                3.0   \n","\n","   edhrecRank  edhrecSaltiness  \\\n","0      9173.0             0.44   \n","1      3003.0             0.30   \n","2     10754.0             0.00   \n","3     21203.0             0.00   \n","4      1921.0             1.72   \n","\n","                                          flavorText                keywords  \\\n","0  He answers questions as readily as he asks the...  ['Flying', 'Hexproof']   \n","1  To become king of the Goblins, one must assass...                ['None']   \n","2                                               None              ['Morbid']   \n","3               \"May the earth rise up to meet you.\"             ['Cycling']   \n","4  The law is meant to ensure that people kill ea...                ['None']   \n","\n","                                          legalities  ... power    rarity  \\\n","0  {'commander': 'Legal', 'duel': 'Legal', 'legac...  ...     5    mythic   \n","1  {'commander': 'Legal', 'duel': 'Legal', 'legac...  ...     2      rare   \n","2  {'commander': 'Legal', 'duel': 'Legal', 'legac...  ...     0    common   \n","3  {'commander': 'Legal', 'duel': 'Legal', 'legac...  ...     3    common   \n","4  {'brawl': 'Legal', 'commander': 'Legal', 'duel...  ...     0  uncommon   \n","\n","                                             rulings setCode  subtypes  \\\n","0  [{'date': '2016-01-22', 'text': 'A spell that ...    POGW    Sphinx   \n","1  [{'date': '2005-08-01', 'text': 'Goblin King n...     3ED    Goblin   \n","2  [{'date': '2011-09-22', 'text': 'You can choos...     ISD      None   \n","3  [{'date': '2008-10-01', 'text': 'Cycling is an...     ARB  Minotaur   \n","4  [{'date': '2019-07-12', 'text': 'If you cast a...     M20      None   \n","\n","  supertypes                                               text toughness  \\\n","0       None  This spell can't be countered.\\nFlying, hexpro...         5   \n","1       None     Other Goblins get +1/+1 and have mountainwalk.         2   \n","2       None  Search your library for a basic land card, rev...         0   \n","3       None  When this_card enters the battlefield, it deal...         4   \n","4       None  Each player can't cast more than one spell eac...         0   \n","\n","                  type        types  \n","0    Creature — Sphinx     Creature  \n","1    Creature — Goblin     Creature  \n","2              Sorcery      Sorcery  \n","3  Creature — Minotaur     Creature  \n","4          Enchantment  Enchantment  \n","\n","[5 rows x 23 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["try:\n","  import google.colab\n","  IN_COLAB = True\n","except:\n","  IN_COLAB = False\n","\n","if(IN_COLAB):\n","    import gdown\n","    output_file = './mtgjson_dataset/cards_nlp.csv'\n","    file_url = 'https://drive.google.com/file/d/1j2e1Va8Tt6bccRUdXEahsJMZD2J1o7ds/view?usp=drive_link'\n","    gdown.download(url = file_url, output = output_file, fuzzy=True)\n","\n","data = pd.read_csv('./mtgjson_dataset/cards_nlp.csv')\n","print('There are',data.shape[0],'unique cards/documents')\n","data.head(5)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1791,"status":"ok","timestamp":1719861739964,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"YktNei8SLUz5","outputId":"15c61edf-0219-49c6-8aac-ce7efbab442e"},"outputs":[],"source":["from gensim.models import Word2Vec\n","\n","if(IN_COLAB):\n","    import gdown\n","    output_file = './mtgjson_dataset/mtg_skipgram.pkl'\n","    file_url = 'https://drive.google.com/file/d/1k5Vv-ikNcf8GMB_DoSLnZjEar1K2E3Cn/view?usp=drive_link'\n","    gdown.download(url = file_url, output = output_file, fuzzy=True)\n","\n","mtg_skipgram = Word2Vec.load('./mtgjson_dataset/mtg_skipgram.pkl')"]},{"cell_type":"markdown","metadata":{"id":"1M-CL0eFJGgg"},"source":["## Preprocessing\n","Lets start by seeking the maximum length for the input sequence. The vanilla dataset longest is an special token that's not legal. After dropping the types _Dungeon_ and _Card_, the longest playable test from a card (as of june 2024) is 113 words from Master of the Hunt (the official text from that card explains the _Band_ keyword which is famously complicated.)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1088,"status":"ok","timestamp":1719861741050,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"ArWuK_vkJGgg","outputId":"22208c3c-f008-4f87-bab1-7bdcc463c302"},"outputs":[{"name":"stdout","output_type":"stream","text":["Longest sequence 264\n","Index of longest sequence 27694\n"]}],"source":["print(\"Longest sequence\", data.text.str.split(\"\\\\s+\").str.len().max())\n","print(\"Index of longest sequence\", data.text.str.split(\"\\\\s+\").str.len().idxmax())"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":656,"status":"ok","timestamp":1719861741704,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"lMtCUZYsJGgh","outputId":"3cfaf326-5e33-429c-89a2-71ab34026a82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Longest sequence of a playable card is 113\n"]},{"data":{"text/plain":["'Master of the Hunt'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["## Cards, Dungeon types are dropped as they are not playable.\n","max_sequence_length = data.loc[(data.type != 'Card') & (data.type != 'Dungeon')].text.str.split(\"\\\\s+\").str.len().max()\n","\n","print(\"Longest sequence of a playable card is\",max_sequence_length)\n","data.loc[(data.type != 'Card') & (data.type != 'Dungeon')].text.str.split(\"\\\\s+\").str.len().idxmax()\n","data.loc[27014,'name']"]},{"cell_type":"markdown","metadata":{"id":"usjlT8V9JGgh"},"source":["### Vectorizer\n","The TextVectorization layer from Keras can handle the tokenization and also can be used in the model pipeline after an Input layer (thus accepting tensors and the model being able to accept string inputs). It can be initialized with a fixed vocabulary. In this case, it will use the previous Gensim vocabulary."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1719861741705,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"BmuFYXAAJGgi","outputId":"aeab77b8-5377-4c91-e6db-c7d947d08b8e"},"outputs":[{"data":{"text/plain":["['', '[UNK]', 'this', 'card', 'a']"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from keras.layers import TextVectorization\n","import tensorflow.strings as tf_strings\n","\n","# Get a custom standarizer that does roughly the same as the default 'strip punctuation and lower' but with a slightly different regex.\n","def standarizer(input):\n","    output = tf_strings.regex_replace(input, r'[!\"#$%&()\\*,\\._:;<=>?@\\[\\\\\\]^`~\\t\\n]', ' ')\n","    output = tf_strings.lower(output)\n","    return output\n","\n","vectorizer = TextVectorization(output_sequence_length=int(max_sequence_length),\n","                               standardize=standarizer,\n","                               # Initialize the Vectorizer state from the Gensim embedding vocabulary\n","                               vocabulary=mtg_skipgram.wv.index_to_key)\n","\n","def sequence_to_text(sequence,vectorizer):\n","    string = ''\n","    try:\n","        iter(sequence)\n","    except:\n","        return vectorizer.get_vocabulary()[sequence]\n","    else:\n","        for index in sequence:\n","            w = vectorizer.get_vocabulary()[index]\n","            string+= w\n","            if(w!=''): string+=\" \"\n","        return string.strip()\n","\n","vectorizer.get_vocabulary()[:5]"]},{"cell_type":"markdown","metadata":{"id":"jyZgQFBFJGgi"},"source":["Note how the layer already set up two special indexes: the 0 for empty (used in padding sequences) and 1 for _unkeyed_, for when words are not found in the vocab. This, of course, expands the vocabulary by 2."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1719861741705,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"mmda-M0PJGgj","outputId":"6180e6f5-71e2-441f-d6b4-27c9a9cc3b34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Vocabulary size: 2195\n"]}],"source":["total_tokens = len(vectorizer.get_vocabulary())\n","embedding_dim = mtg_skipgram.wv.vector_size\n","print(\"Vocabulary size:\", total_tokens)"]},{"cell_type":"markdown","metadata":{"id":"4NYYKNMpJGgj"},"source":["### Embedding mapping\n","As the model will use a pretrained Embedding, it is required to map the newly created tokens to their actual vectors in that Embedding.  Since the tokenizer has been initialized with the same vocabulary as the Gensim embedding, the indexes will be the same but with addition of the empty and unkeyed arrays."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1719861741705,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"_6395oGvJGgj","outputId":"ea71a826-e356-46c2-f6d6-958c0e2c676a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Embedding input dimension is 2195\n","Embedding output dimension is 300\n"]}],"source":["from keras.layers import Embedding\n","\n","# Create two rows of embedding_dim size and then add to it the Gensim raw numpy vectors.\n","embedding_matrix = np.zeros((2,embedding_dim))\n","embedding_matrix = np.append(embedding_matrix,mtg_skipgram.wv.vectors,axis=0)\n","\n","# Keras embedding layer initialized to embedding matrix.\n","embedding_layer = Embedding(\n","    total_tokens,\n","    embedding_dim,\n","    trainable=False,\n",")\n","embedding_layer.build((1,))\n","embedding_layer.set_weights([embedding_matrix])\n","print(\"Embedding input dimension is\",embedding_layer.input_dim)\n","print(\"Embedding output dimension is\",embedding_layer.output_dim)"]},{"cell_type":"markdown","metadata":{"id":"baFnTI75JGgj"},"source":["### Train/test split\n","Setting the learning problema as many-to-one; that is, the network will try to predict the next word given a sequence."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1719861741705,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"UKCflXgmJGgk","outputId":"16f67f8a-80ba-4b9a-f873-f13bef2f4719"},"outputs":[{"data":{"text/plain":["array([[ 43,  28,   2, ...,   0,   0,   0],\n","       [515,   6, 646, ...,   0,   0,   0],\n","       [ 45,   6,  66, ...,   0,   0,   0],\n","       ...,\n","       [ 32,  25,   8, ...,   0,   0,   0],\n","       [  1,  55,  81, ...,   0,   0,   0],\n","       [ 45,   6,  66, ...,   0,   0,   0]], dtype=int64)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, _, _ = train_test_split(data.text,\n","                                         data.text,\n","                                         test_size=0.2,\n","                                         random_state=42)\n","\n","def prepare_training_target_sequence(x):\n","    # Obtain an array of the last word index for target labels,\n","    # and set that same word as 0 for the input set.\n","\n","    # Get that last non-zero element by cumsum and then the index of the\n","    # first max (since the sum won't get higher after the last non-zero).\n","    # Finally get the elements by ways of indexing.\n","    y = x[np.arange(x.shape[0]),(x!=0).cumsum(1).argmax(1)]\n","    x[np.arange(x.shape[0]),(x!=0).cumsum(1).argmax(1)] = 0\n","    return x,y\n","\n","x,y = prepare_training_target_sequence(vectorizer(X_train).numpy())\n","x"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1719861742179,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"2cjfObXsJGgk","outputId":"39061182-f615-4c81-e364-ea86757a4354"},"outputs":[{"name":"stdout","output_type":"stream","text":["when this card dies each player loses 3\n","life\n"]}],"source":["print(sequence_to_text(x[250],vectorizer))\n","print(sequence_to_text(y[250],vectorizer))"]},{"cell_type":"markdown","metadata":{"id":"-TXSM2XQJGgk"},"source":["## Model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1719861742179,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"wfAckR6QJGgl"},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow import data\n","from keras import layers\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding, Dropout\n","from keras.losses import SparseCategoricalCrossentropy"]},{"cell_type":"markdown","metadata":{"id":"j77vgQF0JGgl"},"source":["### Long-short term memory units (LSTM)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1719861742674,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"_9PyVHL0JGgl","outputId":"d8f2ccc0-0f10-42ba-d6df-c7a8044f399c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 113, 300)          658500    \n","                                                                 \n"," lstm (LSTM)                 (None, 113, 64)           93440     \n","                                                                 \n"," dropout (Dropout)           (None, 113, 64)           0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dense (Dense)               (None, 32)                2080      \n","                                                                 \n"," dense_1 (Dense)             (None, 2195)              72435     \n","                                                                 \n","=================================================================\n","Total params: 859,479\n","Trainable params: 200,979\n","Non-trainable params: 658,500\n","_________________________________________________________________\n"]}],"source":["model = Sequential()\n","model.add(keras.Input(shape=(max_sequence_length,)))\n","model.add(embedding_layer)\n","model.add(LSTM(64, return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(64))\n","model.add(Dense(32, activation='relu'))\n","model.add(Dense(total_tokens, activation='softmax'))\n","# Using SparseCategorical as the softmax functions returns the index of the most probable word instead of\n","# OneHot encoding of probabilities.\n","model.compile(loss=SparseCategoricalCrossentropy(), optimizer='adam', metrics='accuracy')\n","\n","model.summary()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1719861742674,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"uaGyN-7KJGgl","outputId":"0238625b-ea1b-4d29-8c34-d19d22a02437"},"outputs":[{"name":"stdout","output_type":"stream","text":["Num GPUs Available:  1\n"]}],"source":["import tensorflow\n","print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))"]},{"cell_type":"markdown","metadata":{},"source":["### Perplexity metric\n","Any deep (supervised) learning model can be generalized as an estimation of the conditional probability distribution of a given experiment: $$ p_{model} = \\hat{P}(y|x_1,x_2...x_n)$$ which is obtained by ways of minimizing the Kullback–Leibler (KL) divergence $$ D_{KL}(p_{data}||p_{model}) = \\mathbb{E}_{x \\sim p_{data}} \\left[\\log \\frac{p_{data}}{p_{model}}\\right] $$\n","which measures, in short, how different two distributions are. It is equivalent to minimizing the cross-entropy or maximizing the likelihood function. The density $p_{model}$ will vary according to the model, the most common ones being Gaussian distributions (regression), Bernoulli distributions (logistic regressions) and Multinoulli distributions (multinomial).\n","\n","Unlike Naive Bayes, which assumed independancy between samples allowing $ p_{model} = \\hat{P}(y|x_1,x_2...x_n) = \\prod_{n} P(y|x_i)$, recurrent neural networks assume the order of the samples matter and are not independent. A RNN models the probability distribution of a certain term appearing inmediately after the samples $$ p_{model} = \\hat{P}(x_{i+1}|x_1,x_2...x_i)$$\n","\n","Then, the probability $P(\\vec w)$ of a certain sentence made of samples $ \\vec w = [w_1,w_2,w_3,...,w_n] $ becomes: $$ P(\\vec w) = P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)...P(w_n|w_1,w_2,...w_{n-1})$$\n","As stated, each term is the output of an RNN (with softmax output) when fed the corresponding sequence. **A good metric for such a model is how likely it is to produce sentences in the validation set**. The perplexity is such a metric, given by the reciprocal of the normalized probability. Taking logs for easier computation, the perplexity expression is $$PPL(\\vec w) = \\exp\\left[-\\frac{1}{t}\\sum_{i}^t \\log P(w_i|w_{<i})\\right]$$"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["x_test,y_test = prepare_training_target_sequence(vectorizer(X_test).numpy())"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from tensorflow.keras.utils import pad_sequences\n","\n","class PplCallback(keras.callbacks.Callback):\n","\n","    def __init__(self, val_data, max_sequence_length):\n","        self.val_data = val_data\n","        self.target = []\n","        self.padded = []\n","        count = 0\n","        self.info = []\n","        for seq in val_data:\n","            seq = np.trim_zeros(seq)\n","            len_seq = len(seq)\n","            subseq = [seq[:i] for i in range(len_seq)]\n","            self.target.extend([seq[i] for i in range(len_seq)])\n","            if len(subseq)!=0:\n","                self.padded.append(pad_sequences(subseq, maxlen=max_sequence_length, padding='pre'))\n","                self.info.append((count,count+len_seq))\n","                count += len_seq\n","        self.padded = np.vstack(self.padded)\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        scores = []\n","        predictions = self.model.predict(self.padded,verbose=0)\n","        for start,end in self.info:\n","          probs = [predictions[idx_seq,idx_vocab] for idx_seq, idx_vocab in zip(range(start,end),self.target[start:end])]\n","          scores.append(np.exp(-np.sum(np.log(probs))/(end-start)))\n","        print(f'\\n mean perplexity: {np.mean(scores)} \\n')\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training\n","The perplexity metric above proved too expensive, so I am training with a simple accuracy score."]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","724/724 [==============================] - 10s 13ms/step - loss: 0.1137 - accuracy: 0.9601\n","Epoch 2/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1151 - accuracy: 0.9593\n","Epoch 3/100\n","724/724 [==============================] - 10s 14ms/step - loss: 0.1154 - accuracy: 0.9602\n","Epoch 4/100\n","724/724 [==============================] - 10s 14ms/step - loss: 0.1196 - accuracy: 0.9594\n","Epoch 5/100\n","724/724 [==============================] - 10s 14ms/step - loss: 0.1127 - accuracy: 0.9603\n","Epoch 6/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1147 - accuracy: 0.9602\n","Epoch 7/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1090 - accuracy: 0.9612\n","Epoch 8/100\n","724/724 [==============================] - 10s 13ms/step - loss: 0.1217 - accuracy: 0.9573\n","Epoch 9/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1118 - accuracy: 0.9611\n","Epoch 10/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1115 - accuracy: 0.9604\n","Epoch 11/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1148 - accuracy: 0.9594\n","Epoch 12/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1139 - accuracy: 0.9610\n","Epoch 13/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1072 - accuracy: 0.9626\n","Epoch 14/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1098 - accuracy: 0.9605\n","Epoch 15/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1181 - accuracy: 0.9583\n","Epoch 16/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1097 - accuracy: 0.9617\n","Epoch 17/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1069 - accuracy: 0.9620\n","Epoch 18/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1089 - accuracy: 0.9611\n","Epoch 19/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1103 - accuracy: 0.9611\n","Epoch 20/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1276 - accuracy: 0.9575\n","Epoch 21/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1164 - accuracy: 0.9601\n","Epoch 22/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1036 - accuracy: 0.9635\n","Epoch 23/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0984 - accuracy: 0.9643\n","Epoch 24/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0987 - accuracy: 0.9644\n","Epoch 25/100\n","724/724 [==============================] - 8s 12ms/step - loss: 0.1127 - accuracy: 0.9610\n","Epoch 26/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1075 - accuracy: 0.9616\n","Epoch 27/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1168 - accuracy: 0.9604\n","Epoch 28/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1057 - accuracy: 0.9619\n","Epoch 29/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1027 - accuracy: 0.9629\n","Epoch 30/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1155 - accuracy: 0.9600\n","Epoch 31/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1090 - accuracy: 0.9619\n","Epoch 32/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1019 - accuracy: 0.9636\n","Epoch 33/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1004 - accuracy: 0.9646\n","Epoch 34/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1045 - accuracy: 0.9622\n","Epoch 35/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1048 - accuracy: 0.9622\n","Epoch 36/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1107 - accuracy: 0.9617\n","Epoch 37/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1121 - accuracy: 0.9613\n","Epoch 38/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1090 - accuracy: 0.9630\n","Epoch 39/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1115 - accuracy: 0.9617\n","Epoch 40/100\n","724/724 [==============================] - 8s 12ms/step - loss: 0.1041 - accuracy: 0.9615\n","Epoch 41/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1002 - accuracy: 0.9629\n","Epoch 42/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1107 - accuracy: 0.9611\n","Epoch 43/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1052 - accuracy: 0.9628\n","Epoch 44/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1032 - accuracy: 0.9635\n","Epoch 45/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1023 - accuracy: 0.9641\n","Epoch 46/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1052 - accuracy: 0.9629\n","Epoch 47/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1075 - accuracy: 0.9606\n","Epoch 48/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1028 - accuracy: 0.9638\n","Epoch 49/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1030 - accuracy: 0.9632\n","Epoch 50/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1046 - accuracy: 0.9630\n","Epoch 51/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1118 - accuracy: 0.9614\n","Epoch 52/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1035 - accuracy: 0.9630\n","Epoch 53/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0986 - accuracy: 0.9654\n","Epoch 54/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1033 - accuracy: 0.9634\n","Epoch 55/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1022 - accuracy: 0.9637\n","Epoch 56/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1023 - accuracy: 0.9626\n","Epoch 57/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1114 - accuracy: 0.9614\n","Epoch 58/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1038 - accuracy: 0.9636\n","Epoch 59/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1076 - accuracy: 0.9621\n","Epoch 60/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1026 - accuracy: 0.9647\n","Epoch 61/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0999 - accuracy: 0.9643\n","Epoch 62/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1078 - accuracy: 0.9634\n","Epoch 63/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0990 - accuracy: 0.9649\n","Epoch 64/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1033 - accuracy: 0.9645\n","Epoch 65/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1078 - accuracy: 0.9622\n","Epoch 66/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0966 - accuracy: 0.9647\n","Epoch 67/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1049 - accuracy: 0.9629\n","Epoch 68/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1040 - accuracy: 0.9629\n","Epoch 69/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1017 - accuracy: 0.9640\n","Epoch 70/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1009 - accuracy: 0.9645\n","Epoch 71/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1010 - accuracy: 0.9632\n","Epoch 72/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0986 - accuracy: 0.9644\n","Epoch 73/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0954 - accuracy: 0.9655\n","Epoch 74/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0972 - accuracy: 0.9647\n","Epoch 75/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0972 - accuracy: 0.9644\n","Epoch 76/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1021 - accuracy: 0.9644\n","Epoch 77/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0930 - accuracy: 0.9669\n","Epoch 78/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0996 - accuracy: 0.9636\n","Epoch 79/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0965 - accuracy: 0.9651\n","Epoch 80/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1011 - accuracy: 0.9645\n","Epoch 81/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0996 - accuracy: 0.9640\n","Epoch 82/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0985 - accuracy: 0.9645\n","Epoch 83/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0971 - accuracy: 0.9655\n","Epoch 84/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1038 - accuracy: 0.9623\n","Epoch 85/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0942 - accuracy: 0.9663\n","Epoch 86/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1003 - accuracy: 0.9640\n","Epoch 87/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0972 - accuracy: 0.9642\n","Epoch 88/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0971 - accuracy: 0.9653\n","Epoch 89/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0964 - accuracy: 0.9658\n","Epoch 90/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0952 - accuracy: 0.9651\n","Epoch 91/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1043 - accuracy: 0.9635\n","Epoch 92/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0965 - accuracy: 0.9655\n","Epoch 93/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0899 - accuracy: 0.9676\n","Epoch 94/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0981 - accuracy: 0.9642\n","Epoch 95/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.1016 - accuracy: 0.9642\n","Epoch 96/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0956 - accuracy: 0.9644\n","Epoch 97/100\n","724/724 [==============================] - 9s 12ms/step - loss: 0.0982 - accuracy: 0.9651\n","Epoch 98/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0942 - accuracy: 0.9655\n","Epoch 99/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.1007 - accuracy: 0.9643\n","Epoch 100/100\n","724/724 [==============================] - 9s 13ms/step - loss: 0.0923 - accuracy: 0.9658\n"]}],"source":["hist = model.fit(x, y, epochs=100, batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["### Save model"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["model.save_weights('./mtgjson_dataset/models/mtg_lstm.weights.h5')"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["model.load_weights('./mtgjson_dataset/models/mtg_lstm.weights.h5')"]},{"cell_type":"markdown","metadata":{},"source":["### Simple sequence generation\n","With this method, simply concatenate a single output to the input sequence and get another prediction, until satisfied. This method is easy, but deterministic and tends to loop if a certain set of words have considerable higher probability that others.\n","\n","To avoid that, Beam Search con be used (see below)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def generate_sequence(input,size,model,vectorizer):\n","    \n","    seq = input\n","    for i in range(size):\n","        preds = model.predict(tensorflow.reshape(vectorizer(seq),(1,-1)), verbose=False)\n","        seq += \" \" +  np.array(vectorizer.get_vocabulary())[np.argmax(preds,axis=1)][0]\n","    return seq"]},{"cell_type":"markdown","metadata":{},"source":["\"Target land gets\" is a simple enough start to try things. Results is not bad."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"data":{"text/plain":["'target land gets +3/+3 trample lifelink haste trample indestructible haste'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["generate_sequence(\"target land gets\", 7 , model,vectorizer)"]},{"cell_type":"markdown","metadata":{},"source":["Here is an instance of the above mentioned. Keywords like _trample_, _flying_, _lifelink_ are entirely too common and this kind of generations tend to get stuck."]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["'whenever a creature token trample reach trample trample trample lifelink'"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["generate_sequence(\"whenever a creature\", 7 , model,vectorizer)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["'if an effect haste trample'"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["generate_sequence(\"if an effect\", 2 , model,vectorizer)"]},{"cell_type":"markdown","metadata":{},"source":["## Beam search"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["from scipy.special import softmax\n","\n","def select_candidates(pred,num_beams,vocab_size,history_probs,history_tokens,temp=1,mode='det'):\n","\n","  pred_large = []\n","\n","  for idx,pp in enumerate(pred):\n","    pred_large.extend(np.log(pp+1E-10)+history_probs[idx])\n","\n","  pred_large = np.array(pred_large)\n","\n"," \n","  if mode == 'det':\n","    idx_select = np.argsort(pred_large)[::-1][:num_beams]\n","  elif mode == 'sto':\n","    idx_select = np.random.choice(np.arange(pred_large.shape[0]), num_beams, p=softmax(pred_large/temp))\n","  else:\n","    raise ValueError(f'Wrong selection mode. {mode} was given. det and sto are supported.')\n","  new_history_tokens = np.concatenate((np.array(history_tokens)[idx_select//vocab_size],\n","                        np.array([idx_select%vocab_size]).T),\n","                      axis=1)\n","\n","  return pred_large[idx_select.astype(int)], new_history_tokens.astype(int)\n","\n","\n","def beam_search(model,num_beams,num_words,input, encode, temp = 1, mode = 'det'):\n","    encoded = encode(input)\n","    y_hat = np.squeeze(model.predict(encoded,verbose=False))\n","    vocab_size = y_hat.shape[0]\n","    history_probs = [0]*num_beams\n","    history_tokens = [encoded[0]]*num_beams\n","    history_probs, history_tokens = select_candidates([y_hat],\n","                                        num_beams,\n","                                        vocab_size,\n","                                        history_probs,\n","                                        history_tokens,\n","                                        temp=temp,\n","                                        mode=mode)\n","\n","    for i in range(num_words-1):\n","      preds = []\n","      for hist in history_tokens:\n","        input_update = np.array([hist[i+1:]]).copy()\n","        y_hat = np.squeeze(model.predict(input_update,verbose=False))\n","\n","        preds.append(y_hat)\n","\n","      history_probs, history_tokens = select_candidates(preds,\n","                                                        num_beams,\n","                                                        vocab_size,\n","                                                        history_probs,\n","                                                        history_tokens,\n","                                                        temp=temp,\n","                                                        mode=mode)\n","\n","    return history_tokens"]},{"cell_type":"markdown","metadata":{},"source":["### Results\n","Non-deterministic beam seach will output a different result each time. Increasing the temperature argument avoids the loop problem but the resulting sequence will be increasingly non-sensical."]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"data":{"text/plain":["'whenever a creature token card auras flying flying flying'"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["def encode(input):\n","    return tensorflow.reshape(vectorizer(input),(1,-1))\n","                       \n","out = beam_search(model,num_beams=5,num_words=6,input=\"whenever a creature\",mode='sto',encode=encode, temp=1)\n","sequence_to_text(out[0],vectorizer)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["\"whenever a creature {4}{w}{u} crewed centaur hydra's {r}{r} −3\""]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["out = beam_search(model,num_beams=5,num_words=6,input=\"whenever a creature\",mode='sto',encode=encode, temp=10)\n","sequence_to_text(out[0],vectorizer)"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["'whenever a creature {3}{b} modifications nearest itself {x}'"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["out = beam_search(model,num_beams=5,num_words=5,input=\"whenever a creature\",mode='sto',encode=encode, temp=25)\n","sequence_to_text(out[0],vectorizer)"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/plain":["'whenever a creature reduced do kaldra chroma zombie'"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["out = beam_search(model,num_beams=5,num_words=5,input=\"whenever a creature\",mode='sto',encode=encode, temp=50)\n","sequence_to_text(out[0],vectorizer)"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["'if an effect won −10 saproling: bloodthirst beginning'"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["out = beam_search(model,num_beams=5,num_words=5,input=\"if an effect\",mode='sto',encode=encode, temp=50)\n","sequence_to_text(out[0],vectorizer)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
