{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1235,"status":"ok","timestamp":1719440573253,"user":{"displayName":"Javier Cambiasso","userId":"05968496335944626272"},"user_tz":180},"id":"UlOzVhfKerFF"},"outputs":[],"source":["import requests\n","import os\n","import json\n","import pandas as pd\n","import numpy as np\n","import io\n","\n","def get_dataset(output_dir:str,output_file:str,url:str, encoding = 'utf8'):\n","    response = requests.get(url + '.sha256' )\n","    requires_update = False\n","    try:\n","        outf = open(os.path.join(output_dir,output_file + '.sha256'),'rt')\n","        if outf.read() != response.text:\n","            requires_update = True\n","        outf.close()\n","    except:\n","        requires_update = True\n","\n","    if(requires_update):\n","        with open(os.path.join(output_dir,output_file + '.sha256'), 'wt') as outf:\n","            outf.write(response.text)\n","            outf.close()\n","\n","        response = requests.get(url)\n","        with open(os.path.join(output_dir,output_file), 'wt', encoding = encoding) as outf:\n","            outf.write(response.text)\n","            outf.close()\n","\n","        print(output_file,'updated')\n","    return"]},{"cell_type":"markdown","metadata":{},"source":["Get all the mtgjson files needed."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["dataset_path = \"./mtgjson_dataset\"\n","keywords_file = 'Keywords.json'\n","sets_file = 'SetList.json'\n","types_file = 'CardTypes.json'\n","identifiers_file = 'AllIdentifiers.json'\n","\n","get_dataset(dataset_path, keywords_file, \"http://mtgjson.com/api/v5/Keywords.json\")\n","get_dataset(dataset_path, sets_file, \"http://mtgjson.com/api/v5/SetList.json\")\n","get_dataset(dataset_path, types_file, \"http://mtgjson.com/api/v5/CardTypes.json\")\n","get_dataset(dataset_path, identifiers_file , \"http://mtgjson.com/api/v5/AllIdentifiers.json\")"]},{"cell_type":"markdown","metadata":{},"source":["## Keywords database"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#Obtain an useful list of keywords\n","keywords_raw = pd.read_json(os.path.join(dataset_path,keywords_file))\n","abilityWords = keywords_raw.data.at['abilityWords']\n","keywordAbilities = keywords_raw.data.at['keywordAbilities']\n","keywordActions = keywords_raw.data.at['keywordActions']"]},{"cell_type":"markdown","metadata":{},"source":["## Types database"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["types_raw = pd.read_json(os.path.join(dataset_path,types_file))\n","creatureTypes_raw = types_raw.data.at['creature']\n","creatureTypes = creatureTypes_raw['subTypes']"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["j = json.load(open(os.path.join(dataset_path,sets_file),encoding='UTF8'))\n","sets = pd.DataFrame(j['data'])"]},{"cell_type":"markdown","metadata":{},"source":["## Main card database\n","### Get all Cards by UUID\n","We are going to deal with gameplay features, so everything not directly impacting it gets dropped. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["cards_set_data = pd.read_json(os.path.join(dataset_path,identifiers_file)).data.drop(index=['date','version'])\n","data = pd.read_json(io.StringIO(json.dumps(cards_set_data.reset_index(drop=True).to_list())))\n","del cards_set_data\n","\n","# Minor sanitation\n","\n","# Drop duplicates based on name; gameplay-wise, same name is the same card and a duplicate.\n","data = data.drop_duplicates(['name'])\n","# Quick and obvious feature selection\n","# Drop all columns with a high percent of nulls\n","null_threshold = 90.0\n","data = data.drop(np.array(data.columns)[pd.Series(data.isnull().sum() * 100 / len(data)) >= null_threshold],axis=1)\n","# Drop commercial, duplicate identifiers and artistitc data.\n","artistic_features = ['borderColor', 'finishes', 'foreignData', 'frameVersion','securityStamp','frameEffects','layout']\n","commercial_features = ['sourceProducts','variations','hasFoil','hasNonFoil','promoTypes','purchaseUrls','isReprint', 'isStarter','boosterTypes','availability']\n","# I will leave the card name for now.\n","identifier_features = ['uuid','originalText','originalType','identifiers','language','number','printings','artistIds']\n","data = data.drop(artistic_features,axis=1).drop(commercial_features,axis=1).drop(identifier_features,axis=1)\n","# Not so obivious filtering: the 'un-sets' are weird and will add unnecessary noise. \n","unsets_codes = ['UGL','UNH','UST','UND','UNF']\n","data = data.loc[~data.setCode.isin(unsets_codes)]"]},{"cell_type":"markdown","metadata":{},"source":["### Missing values imputation"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Some useful definitions\n","# Given a pd.Series with List values, checks if any of those are in keywords. Returns a dummy pandas frame with keywords.shape features.\n","def ListOneHot(X, y=None, keywords=None, count_threshold=0):\n","    result = pd.DataFrame(X.apply(lambda x: np.in1d(keywords,np.array(x))).to_list(),columns=keywords, index=X.index).astype(bool)\n","    return result\n","# Givem a pd.Series with string values, check if any contains the string in keywords. Returns a dummy pandas frame with keywords.shape features.\n","def StringOneHot(X, y=None, keywords=None, count_threshold=0):\n","    frames = []\n","    for keyword in keywords:\n","        frames.append(X.fillna(\"\").str.contains(keyword,regex=True,case=False).to_numpy())\n","    result =  pd.DataFrame(np.array(frames).transpose(),columns=keywords, index = X.index).astype(bool)\n","    return result\n","\n","# Empty mana cost, converted mana cost and mana value just mean that, empty. I will replace with an \"none' value for each one.\n","data.convertedManaCost = data.convertedManaCost.fillna(0.0)\n","data.manaCost = data.manaCost.fillna('None')\n","data.manaValue = data.manaValue.fillna(0.0)\n","# A null edhrec rank means mostly terrible cards for commander, setting the null for the max (worse) rank.\n","data.edhrecRank = data.edhrecRank.fillna(data.edhrecRank.max())\n","# Same for saltiness, not saltiness means not votes at all = 0.0 salt.\n","data.edhrecSaltiness = data.edhrecSaltiness.fillna(0.0)\n","# Flavor null is just empty.\n","data.flavorText = data.flavorText.fillna('None')\n","# Null keywords mean no keywords\n","data.keywords = data.keywords.apply(lambda x: ['None'] if (pd.Series(x,dtype='object').isnull().any() or (str(x) == '')) else x)\n","data.subtypes = data.subtypes.apply(lambda x: ['None'] if (pd.Series(x,dtype='object').isnull().any() or (str(x) == '')) else x)\n","data.supertypes = data.supertypes.apply(lambda x: ['None'] if (pd.Series(x,dtype='object').isnull().any() or (str(x) == '')) else x)\n","data.types = data.types.apply(lambda x: ['None'] if (pd.Series(x,dtype='object').isnull().any() or (str(x) == '')) else x)\n","# Same for legalities\n","data.legalities = data.legalities.apply(lambda x: {'None':None}  if (pd.Series(x,dtype='object').isnull().any() or str(x) == '') else x)\n","# Most are tokens, and the other 4 are instances too. They don't have a rarity per se, but it is guaranteed drop on each booster. So, lets default to Common.\n","data.rarity = data.rarity.fillna('common')\n","# Cards with no rules have rulings as NaN. Just fill with empty string\n","data.rulings = data.rulings.fillna('None')\n","# Same with text\n","data.text = data.text.fillna('None')\n","# Complete empty artists\n","data.artist = data.artist.fillna('None')\n","# Impute power and toughness as 0\n","data.power = data.power.fillna(0)\n","data.toughness = data.toughness.fillna(0)\n","data.setCode = data.setCode.fillna('None')\n","data.type = data.type.fillna('None')\n","\n","colors = ['W','U','B','R','G']\n","def list_to_color_string(series):\n","    result = ''\n","    if(series.W): result +='W'\n","    if(series.U): result +='U'\n","    if(series.B): result +='B'\n","    if(series.R): result +='R'\n","    if(series.G): result +='G'\n","    if(result == ''): result = 'C' \n","    return result\n","\n","data['colors'] = ListOneHot(X=data.colors, keywords=colors).apply(list_to_color_string,axis=1)\n","data['colorIdentity'] = ListOneHot(X=data.colorIdentity, keywords=colors).apply(list_to_color_string,axis=1)\n","data.supertypes = data.supertypes.apply(lambda x: ','.join(x))\n","data.loc[data.supertypes == '', 'supertypes'] = 'None'\n","data.subtypes = data.subtypes.apply(lambda x: ','.join(x))\n","data.loc[data.subtypes == '', 'subtypes'] = 'None'\n","data.types = data.types.apply(lambda x: ','.join(x))\n","data.loc[data.types == '', 'types'] = 'None'\n","\n","if data.isnull().any().any():\n","    raise Exception(\"Thera are NaN values in dataset\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Replace instances of the card name inside its text for a common token.\n","Card names in each sample will lead to noise in any language processing application and the fact that it is referencing itself is sufficient for any analysis."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["self_token = 'this_card'\n","data.text = data.apply(lambda x : x['text'].replace(str(x['name']), self_token), axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Save cards with non-empty text for NLP"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["data.loc[data.text != 'None'].to_csv(os.path.join(dataset_path,'cards_nlp.csv'))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["Series([], Name: subtypes, dtype: object)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["data.subtypes.loc[data.subtypes == '']"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM7JCQ9FScUlr2miln2aq7M","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
